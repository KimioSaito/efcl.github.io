{"version":3,"sources":["../src/no-doubled-joshi.js"],"names":["context","options","helper","minInterval","min_interval","defaultOptions","isStrict","strict","allow","separatorChars","Syntax","report","getSource","RuleError","Paragraph","node","isChildNode","Link","Image","BlockQuote","Emphasis","source","text","toString","isSentenceNode","type","Sentence","sentences","filter","then","checkSentence","sentence","tokens","tokenizer","tokenizeForSentence","raw","countableTokens","token","joshiTokenSurfaceKeyMap","createSurfaceKeyMap","Object","keys","forEach","key","joshiName","indexOf","matchExceptionRule","length","reduce","prev","current","startPosition","otherPosition","differenceIndex","originalIndex","originalIndexFromPosition","line","loc","start","column","word_position","padding","index","keyMap","tokenKey","push","pos_detail_1","surface_form"],"mappings":"AAAA;AACA;;;;;;kBAgEe,UAASA,OAAT,EAAgC;AAAA,QAAdC,OAAc,uEAAJ,EAAI;;AAC3C,QAAMC,SAAS,mCAAeF,OAAf,CAAf;AACA;AACA,QAAMG,cAAcF,QAAQG,YAAR,IAAwBC,eAAeD,YAA3D;AACA,QAAME,WAAWL,QAAQM,MAAR,IAAkBF,eAAeE,MAAlD;AACA,QAAMC,QAAQP,QAAQO,KAAR,IAAiBH,eAAeG,KAA9C;AACA,QAAMC,iBAAiBR,QAAQQ,cAAR,IAA0BJ,eAAeI,cAAhE;AAN2C,QAOpCC,MAPoC,GAOIV,OAPJ,CAOpCU,MAPoC;AAAA,QAO5BC,MAP4B,GAOIX,OAPJ,CAO5BW,MAP4B;AAAA,QAOpBC,SAPoB,GAOIZ,OAPJ,CAOpBY,SAPoB;AAAA,QAOTC,SAPS,GAOIb,OAPJ,CAOTa,SAPS;;AAQ3C,+BACKH,OAAOI,SADZ,YACuBC,IADvB,EAC4B;AACpB,YAAIb,OAAOc,WAAP,CAAmBD,IAAnB,EAAyB,CAACL,OAAOO,IAAR,EAAcP,OAAOQ,KAArB,EAA4BR,OAAOS,UAAnC,EAA+CT,OAAOU,QAAtD,CAAzB,CAAJ,EAA+F;AAC3F;AACH;AACD,YAAMC,SAAS,mCAAiBN,IAAjB,CAAf;AACA,YAAMO,OAAOD,OAAOE,QAAP,EAAb;AACA,YAAMC,iBAAiB,SAAjBA,cAAiB,OAAQ;AAC3B,mBAAOT,KAAKU,IAAL,KAAc,yBAAeC,QAApC;AACH,SAFD;AAGA,YAAIC,YAAY,6BAAeL,IAAf,EAAqB;AACjCb,4BAAgBA;AADiB,SAArB,EAEbmB,MAFa,CAENJ,cAFM,CAAhB;AAGA,eAAO,+BAAeK,IAAf,CAAoB,qBAAa;AACpC,gBAAMC,gBAAgB,SAAhBA,aAAgB,CAACC,QAAD,EAAc;AAChC,oBAAIC,SAASC,UAAUC,mBAAV,CAA8BH,SAASI,GAAvC,CAAb;AACA,oBAAIC,kBAAkBJ,OAAOJ,MAAP,CAAc,iBAAS;AACzC,wBAAItB,QAAJ,EAAc;AACV,+BAAO,2BAAU+B,KAAV,CAAP;AACH;AACD;AACA;AACA;AACA,2BAAO,2BAAUA,KAAV,KAAoB,2BAAUA,KAAV,CAA3B;AACH,iBARqB,CAAtB;AASA,oBAAIC,0BAA0BC,oBAAoBH,eAApB,CAA9B;AACA;;;;;;;;AASAI,uBAAOC,IAAP,CAAYH,uBAAZ,EAAqCI,OAArC,CAA6C,eAAO;AAChD,wBAAMV,SAASM,wBAAwBK,GAAxB,CAAf;AACA,wBAAMC,YAAY,yCAAwBD,GAAxB,CAAlB;AACA;AACA,wBAAInC,MAAMqC,OAAN,CAAcD,SAAd,KAA4B,CAAhC,EAAmC;AAC/B;AACH;AACD;AACA,wBAAI,CAACtC,QAAL,EAAe;AACX,4BAAIwC,mBAAmBd,MAAnB,CAAJ,EAAgC;AAC5B;AACH;AACJ;AACD,wBAAIA,OAAOe,MAAP,IAAiB,CAArB,EAAwB;AACpB,+BADoB,CACb;AACV;AACD;AACA;AACAf,2BAAOgB,MAAP,CAAc,UAACC,IAAD,EAAOC,OAAP,EAAmB;AAC7B,4BAAMC,gBAAgBf,gBAAgBS,OAAhB,CAAwBI,IAAxB,CAAtB;AACA,4BAAMG,gBAAgBhB,gBAAgBS,OAAhB,CAAwBK,OAAxB,CAAtB;AACA;AACA,4BAAMG,kBAAkBD,gBAAgBD,aAAxC;AACA,4BAAIE,mBAAmBlD,WAAvB,EAAoC;AAChC,gCAAMmD,gBAAgBjC,OAAOkC,yBAAP,CAAiC;AACnDC,sCAAMzB,SAAS0B,GAAT,CAAaC,KAAb,CAAmBF,IAD0B;AAEnDG,wCAAQ5B,SAAS0B,GAAT,CAAaC,KAAb,CAAmBC,MAAnB,IAA6BT,QAAQU,aAAR,GAAwB,CAArD;AAF2C,6BAAjC,CAAtB;AAIA;AACA,gCAAMC,UAAU;AACZC,uCAAOR;AADK,6BAAhB;AAGA3C,mCAAOI,IAAP,EAAa,IAAIF,SAAJ,yGAAmC+B,SAAnC,gEAA2DiB,OAA3D,CAAb;AACH;AACD,+BAAOX,OAAP;AACH,qBAjBD;AAkBH,iBApCD;AAqCH,aA1DD;AA2DAvB,sBAAUe,OAAV,CAAkBZ,aAAlB;AACH,SA7DM,CAAP;AA8DH,KA3EL;AA6EH,C;;AApJD;;AACA;;AACA;;AACA;;;;AACA;;;;;;AAIA;;;;;;;;;AASA,SAASS,mBAAT,CAA6BP,MAA7B,EAAqC;AACjC;AACA,WAAOA,OAAOJ,MAAP,wBAAyBoB,MAAzB,CAAgC,UAACe,MAAD,EAAS1B,KAAT,EAAmB;AACtD;AACA,YAAM2B,WAAW,kCAAiB3B,KAAjB,CAAjB;AACA,YAAI,CAAC0B,OAAOC,QAAP,CAAL,EAAuB;AACnBD,mBAAOC,QAAP,IAAmB,EAAnB;AACH;AACDD,eAAOC,QAAP,EAAiBC,IAAjB,CAAsB5B,KAAtB;AACA,eAAO0B,MAAP;AACH,KARM,EAQJ,EARI,CAAP;AASH;AACD,SAASjB,kBAAT,CAA4Bd,MAA5B,EAAoC;AAChC,QAAIK,QAAQL,OAAO,CAAP,CAAZ;AACA;AACA,QAAIK,MAAM6B,YAAN,KAAuB,KAA3B,EAAkC;AAC9B,eAAO,IAAP;AACH;AACD;AACA,QAAI7B,MAAM6B,YAAN,KAAuB,KAAvB,IAAgC7B,MAAM8B,YAAN,KAAuB,GAA3D,EAAgE;AAC5D,eAAO,IAAP;AACH;AACD;AACA,QAAI9B,MAAM6B,YAAN,KAAuB,MAAvB,IAAiC7B,MAAM8B,YAAN,KAAuB,GAA5D,EAAiE;AAC7D,eAAO,IAAP;AACH;AACD,WAAO,KAAP;AACH;AACD;;;AAGA,IAAM9D,iBAAiB;AACnBD,kBAAc,CADK;AAEnBG,YAAQ,KAFW;AAGnBC,WAAO,EAHY;AAInBC,oBAAgB,CAAC,GAAD,EAAM,GAAN,EAAW,GAAX,EAAgB,GAAhB,EAAqB,GAArB;AAJG,CAAvB;;AAOA;;;;;;;;AA6FC","file":"no-doubled-joshi.js","sourcesContent":["// LICENSE : MIT\n\"use strict\";\nimport {RuleHelper} from \"textlint-rule-helper\";\nimport {getTokenizer} from \"kuromojin\";\nimport {split as splitSentences, Syntax as SentenceSyntax} from \"sentence-splitter\";\nimport StringSource from \"textlint-util-to-string\";\nimport {\n    is助詞Token, is読点Token,\n    createKeyFromKey, restoreToSurfaceFromKey\n} from \"./token-utils\";\n/**\n * Create token map object\n * {\n *  \"で\": [token, token],\n *  \"の\": [token, token]\n * }\n * @param tokens\n * @returns {*}\n */\nfunction createSurfaceKeyMap(tokens) {\n    // 助詞のみを対象とする\n    return tokens.filter(is助詞Token).reduce((keyMap, token) => {\n        // \"は:助詞.係助詞\" : [token]\n        const tokenKey = createKeyFromKey(token);\n        if (!keyMap[tokenKey]) {\n            keyMap[tokenKey] = [];\n        }\n        keyMap[tokenKey].push(token);\n        return keyMap;\n    }, {});\n}\nfunction matchExceptionRule(tokens) {\n    let token = tokens[0];\n    // \"の\" の重なりは例外\n    if (token.pos_detail_1 === \"連体化\") {\n        return true;\n    }\n    // \"を\" の重なりは例外\n    if (token.pos_detail_1 === \"格助詞\" && token.surface_form === \"を\") {\n        return true;\n    }\n    // 接続助詞 \"て\" の重なりは例外\n    if (token.pos_detail_1 === \"接続助詞\" && token.surface_form === \"て\") {\n        return true;\n    }\n    return false;\n}\n/*\n default options\n */\nconst defaultOptions = {\n    min_interval: 1,\n    strict: false,\n    allow: [],\n    separatorChars: [\"。\", \"?\", \"!\", \"？\", \"！\"]\n};\n\n/*\n 1. Paragraph Node -> text\n 2. text -> sentences\n 3. tokenize sentence\n 4. report error if found word that match the rule.\n\n TODO: need abstraction\n */\nexport default function(context, options = {}) {\n    const helper = new RuleHelper(context);\n    // 最低間隔値\n    const minInterval = options.min_interval || defaultOptions.min_interval;\n    const isStrict = options.strict || defaultOptions.strict;\n    const allow = options.allow || defaultOptions.allow;\n    const separatorChars = options.separatorChars || defaultOptions.separatorChars;\n    const {Syntax, report, getSource, RuleError} = context;\n    return {\n        [Syntax.Paragraph](node){\n            if (helper.isChildNode(node, [Syntax.Link, Syntax.Image, Syntax.BlockQuote, Syntax.Emphasis])) {\n                return;\n            }\n            const source = new StringSource(node);\n            const text = source.toString();\n            const isSentenceNode = node => {\n                return node.type === SentenceSyntax.Sentence;\n            };\n            let sentences = splitSentences(text, {\n                separatorChars: separatorChars\n            }).filter(isSentenceNode);\n            return getTokenizer().then(tokenizer => {\n                const checkSentence = (sentence) => {\n                    let tokens = tokenizer.tokenizeForSentence(sentence.raw);\n                    let countableTokens = tokens.filter(token => {\n                        if (isStrict) {\n                            return is助詞Token(token);\n                        }\n                        // デフォルトでは、\"、\"を間隔値の距離としてカウントする\n                        // \"、\" があると助詞同士の距離が開くようにすることで、並列的な\"、\"の使い方を許容する目的\n                        // https://github.com/azu/textlint-rule-no-doubled-joshi/issues/2\n                        return is助詞Token(token) || is読点Token(token);\n                    });\n                    let joshiTokenSurfaceKeyMap = createSurfaceKeyMap(countableTokens);\n                    /*\n                     # Data Structure\n\n                     joshiTokens = [tokenA, tokenB, tokenC, tokenD, tokenE, tokenF]\n                     joshiTokenSurfaceKeyMap = {\n                     \"は:助詞.係助詞\": [tokenA, tokenC, tokenE],\n                     \"で:助詞.係助詞\": [tokenB, tokenD, tokenF]\n                     }\n                     */\n                    Object.keys(joshiTokenSurfaceKeyMap).forEach(key => {\n                        const tokens = joshiTokenSurfaceKeyMap[key];\n                        const joshiName = restoreToSurfaceFromKey(key);\n                        // check allow\n                        if (allow.indexOf(joshiName) >= 0) {\n                            return;\n                        }\n                        // strict mode ではない時例外を除去する\n                        if (!isStrict) {\n                            if (matchExceptionRule(tokens)) {\n                                return;\n                            }\n                        }\n                        if (tokens.length <= 1) {\n                            return;// no duplicated token\n                        }\n                        // if found differenceIndex less than\n                        // tokes are sorted ascending order\n                        tokens.reduce((prev, current) => {\n                            const startPosition = countableTokens.indexOf(prev);\n                            const otherPosition = countableTokens.indexOf(current);\n                            // 助詞token同士の距離が設定値以下ならエラーを報告する\n                            const differenceIndex = otherPosition - startPosition;\n                            if (differenceIndex <= minInterval) {\n                                const originalIndex = source.originalIndexFromPosition({\n                                    line: sentence.loc.start.line,\n                                    column: sentence.loc.start.column + (current.word_position - 1)\n                                });\n                                // padding positionを計算する\n                                const padding = {\n                                    index: originalIndex\n                                };\n                                report(node, new RuleError(`一文に二回以上利用されている助詞 \"${joshiName}\" がみつかりました。`, padding));\n                            }\n                            return current;\n                        });\n                    });\n                };\n                sentences.forEach(checkSentence);\n            });\n        }\n    }\n};\n"]}