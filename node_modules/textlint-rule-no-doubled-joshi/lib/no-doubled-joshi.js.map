{"version":3,"sources":["../src/no-doubled-joshi.js"],"names":[],"mappings":";AACA,YAAY,CAAC;;;;;;kBAqCE,UAAU,OAAO,EAAgB;QAAd,OAAO,yDAAG,EAAE;;AAC1C,QAAM,MAAM,GAAG,wBArCX,UAAU,CAqCgB,OAAO,CAAC;;AAAC,AAEvC,QAAI,WAAW,GAAG,OAAO,CAAC,YAAY,IAAI,cAAc,CAAC,YAAY,CAAC;AACtE,QAAI,QAAQ,GAAG,OAAO,CAAC,MAAM,IAAI,cAAc,CAAC,MAAM,CAAC;QAClD,MAAM,GAAkC,OAAO,CAA/C,MAAM;QAAE,MAAM,GAA0B,OAAO,CAAvC,MAAM;QAAE,SAAS,GAAe,OAAO,CAA/B,SAAS;QAAE,SAAS,GAAI,OAAO,CAApB,SAAS;;AACzC,+BACK,MAAM,CAAC,GAAG,YAAE,IAAI,EAAC;AACd,YAAI,MAAM,CAAC,WAAW,CAAC,IAAI,EAAE,CAAC,MAAM,CAAC,IAAI,EAAE,MAAM,CAAC,KAAK,EAAE,MAAM,CAAC,UAAU,EAAE,MAAM,CAAC,QAAQ,CAAC,CAAC,EAAE;AAC3F,mBAAO;SACV;AACD,YAAI,IAAI,GAAG,SAAS,CAAC,IAAI,CAAC,CAAC;AAC3B,YAAI,SAAS,GAAG,gCAAe,IAAI,CAAC,CAAC,MAAM,CAAC,UAAA,IAAI,EAAI;AAChD,mBAAO,IAAI,CAAC,IAAI,KAAK,kBA/Cb,MAAM,CA+CsB,QAAQ,CAAC;SAChD,CAAC,CAAC;AACH,eAAO,eAlDX,YAAY,GAkDa,CAAC,IAAI,CAAC,UAAA,SAAS,EAAI;AACpC,gBAAM,aAAa,GAAG,SAAhB,aAAa,CAAI,QAAQ,EAAK;AAChC,oBAAI,MAAM,GAAG,SAAS,CAAC,mBAAmB,CAAC,QAAQ,CAAC,GAAG,CAAC,CAAC;AACzD,oBAAI,WAAW,GAAG,MAAM,CAAC,MAAM,CAAC,UAAA,KAAK,EAAI;AACrC,2BAAO,KAAK,CAAC,GAAG,KAAK,IAAI,CAAC;iBAC7B,CAAC,CAAC;AACH,oBAAI,uBAAuB,GAAG,mBAAmB,CAAC,WAAW,CAAC;;;;;;;;;AAAC,AAU/D,sBAAM,CAAC,IAAI,CAAC,uBAAuB,CAAC,CAAC,OAAO,CAAC,UAAA,GAAG,EAAI;AAChD,wBAAI,MAAM,GAAG,uBAAuB,CAAC,GAAG,CAAC;;AAAC,AAE1C,wBAAI,CAAC,QAAQ,EAAE;AACX,4BAAG,kBAAkB,CAAC,MAAM,CAAC,EAAE;AAC3B,mCAAO;yBACV;qBACJ;AACD,wBAAI,MAAM,CAAC,MAAM,IAAI,CAAC,EAAE;AACpB;AAAO,qBACV;;AAAA,AAED,0BAAM,CAAC,MAAM,CAAC,UAAC,IAAI,EAAE,OAAO,EAAK;AAC7B,4BAAI,aAAa,GAAG,WAAW,CAAC,OAAO,CAAC,IAAI,CAAC,CAAC;AAC9C,4BAAI,aAAa,GAAG,WAAW,CAAC,OAAO,CAAC,OAAO,CAAC;;AAAC,AAEjD,4BAAI,eAAe,GAAG,aAAa,GAAG,aAAa,CAAC;AACpD,4BAAI,eAAe,IAAI,WAAW,EAAE;AAChC,kCAAM,CAAC,IAAI,EAAE,IAAI,SAAS,yBAAsB,GAAG,mBAAe;AAC9D,oCAAI,EAAE,QAAQ,CAAC,GAAG,CAAC,KAAK,CAAC,IAAI,GAAG,CAAC;;;AAGjC,sCAAM,EAAE,QAAQ,CAAC,GAAG,CAAC,KAAK,CAAC,MAAM,IAAI,OAAO,CAAC,aAAa,GAAG,CAAC,CAAA,AAAC;6BAClE,CAAC,CAAC,CAAC;yBACP;AACD,+BAAO,OAAO,CAAC;qBAClB,CAAC,CAAC;iBACN,CAAC,CAAC;aACN,CAAC;AACF,qBAAS,CAAC,OAAO,CAAC,aAAa,CAAC,CAAC;SACpC,CAAC,CAAC;KACN,EACJ;CACJ;;;;;;;;;;;;;;;;;;;;;;;AAxFD,SAAS,mBAAmB,CAAC,MAAM,EAAE;AACjC,WAAO,MAAM,CAAC,MAAM,CAAC,UAAC,MAAM,EAAE,KAAK,EAAK;;AAEpC,YAAI,CAAC,MAAM,CAAC,KAAK,CAAC,YAAY,CAAC,EAAE;AAC7B,kBAAM,CAAC,KAAK,CAAC,YAAY,CAAC,GAAG,EAAE,CAAC;SACnC;AACD,cAAM,CAAC,KAAK,CAAC,YAAY,CAAC,CAAC,IAAI,CAAC,KAAK,CAAC,CAAC;AACvC,eAAO,MAAM,CAAC;KACjB,EAAE,EAAE,CAAC,CAAC;CACV;AACD,SAAS,kBAAkB,CAAC,MAAM,EAAE;AAChC,QAAI,KAAK,GAAG,MAAM,CAAC,CAAC,CAAC,CAAC;AACtB,QAAI,KAAK,CAAC,YAAY,KAAK,KAAK,EAAE;AAC9B,eAAO,IAAI,CAAC;KACf;AACD,QAAI,KAAK,CAAC,YAAY,KAAK,KAAK,IAAI,KAAK,CAAC,YAAY,KAAK,GAAG,EAAE;AAC5D,eAAO,IAAI,CAAC;KACf;AACD,WAAO,KAAK,CAAC;CAChB;AACD,IAAM,cAAc,GAAG;AACnB,gBAAY,EAAE,CAAC;AACf,UAAM,EAAE,KAAK;CAChB,CAAC;AAiED,CAAC","file":"no-doubled-joshi.js","sourcesContent":["// LICENSE : MIT\n\"use strict\";\nimport {RuleHelper} from \"textlint-rule-helper\";\nimport {getTokenizer} from \"kuromojin\";\nimport splitSentences, {Syntax as SentenceSyntax} from \"sentence-splitter\";\n/**\n * create a object that\n * map ={\n *   // these token.surface_form === \"Hoge\"\n *  \"Hoge\" [token, token]\n * }\n * @param tokens\n * @returns {*}\n */\nfunction createSurfaceKeyMap(tokens) {\n    return tokens.reduce((keyMap, token) => {\n        // \"は\" : [token]\n        if (!keyMap[token.surface_form]) {\n            keyMap[token.surface_form] = [];\n        }\n        keyMap[token.surface_form].push(token);\n        return keyMap;\n    }, {});\n}\nfunction matchExceptionRule(tokens) {\n    let token = tokens[0];\n    if (token.pos_detail_1 === \"連体化\") {\n        return true;\n    }\n    if (token.pos_detail_1 === \"格助詞\" && token.surface_form === \"を\") {\n        return true;\n    }\n    return false;\n}\nconst defaultOptions = {\n    min_interval: 1,\n    strict: false\n};\nexport default function (context, options = {}) {\n    const helper = new RuleHelper(context);\n    // 最低間隔値\n    let minInterval = options.min_interval || defaultOptions.min_interval;\n    let isStrict = options.strict || defaultOptions.strict;\n    let {Syntax, report, getSource, RuleError} = context;\n    return {\n        [Syntax.Str](node){\n            if (helper.isChildNode(node, [Syntax.Link, Syntax.Image, Syntax.BlockQuote, Syntax.Emphasis])) {\n                return;\n            }\n            let text = getSource(node);\n            let sentences = splitSentences(text).filter(node => {\n                return node.type === SentenceSyntax.Sentence;\n            });\n            return getTokenizer().then(tokenizer => {\n                const checkSentence = (sentence) => {\n                    let tokens = tokenizer.tokenizeForSentence(sentence.raw);\n                    let joshiTokens = tokens.filter(token => {\n                        return token.pos === \"助詞\";\n                    });\n                    let joshiTokenSurfaceKeyMap = createSurfaceKeyMap(joshiTokens);\n                    /*\n                    # Data Structure\n\n                        joshiTokens = [tokenA, tokenB, tokenC, tokenD, tokenE, tokenF]\n                        joshiTokenSurfaceKeyMap = {\n                            \"は\": [tokenA, tokenC, tokenE],\n                            \"で\": [tokenB, tokenD, tokenF]\n                        }\n                     */\n                    Object.keys(joshiTokenSurfaceKeyMap).forEach(key => {\n                        let tokens = joshiTokenSurfaceKeyMap[key];\n                        // strict mode ではない時例外を除去する\n                        if (!isStrict) {\n                            if(matchExceptionRule(tokens)) {\n                                return;\n                            }\n                        }\n                        if (tokens.length <= 1) {\n                            return;// no duplicated token\n                        }\n                        // if found differenceIndex less than\n                        tokens.reduce((prev, current) => {\n                            let startPosition = joshiTokens.indexOf(prev);\n                            let otherPosition = joshiTokens.indexOf(current);\n                            // if difference\n                            let differenceIndex = otherPosition - startPosition;\n                            if (differenceIndex <= minInterval) {\n                                report(node, new RuleError(`一文に二回以上利用されている助詞 \"${key}\" がみつかりました。`, {\n                                    line: sentence.loc.start.line - 1,\n                                    // matchLastToken.word_position start with 1\n                                    // this is padding column start with 0 (== -1)\n                                    column: sentence.loc.start.column + (current.word_position - 1)\n                                }));\n                            }\n                            return current;\n                        });\n                    });\n                };\n                sentences.forEach(checkSentence);\n            });\n        }\n    }\n};"]}