---
title: 小説をテキスト化する下ごしらえのTips
author: azu
layout: post
permalink: /2007/1225/res9/
SBM_count:
  - '00004<>1355447606<>2<>1<>0<>1<>0'
dsq_thread_id:
  - 301074833
categories:
  - 小説電子化
tags:
  - e.Typist
  - OCR
  - ソフトウェア
  - テキスト化
  - ライトノベル
  - 小説
---
メモ書きなので、そのうちまとめます。(wikiかなんか作ったほうが良いかな?)  
今回はどのフォーマットで下ごしらえをするべきかを比較しながらやってく。

サンプル作品はSnapScan（300dpi）でスキャンしたものを10数ページ。

**画像ファイルの下ごしらえ**

一般的には文字のようなものはフォーマット的にpngが最適だと思います。

使用ソフトは[MeTilTran][1]と[藤 -Resizer][2]-とe.Typistの3つを使っていきます。  
MeTilTranで画像の角度修正とリサイズの両方の作業ができる、しかしMeTilTranは  
画像の出力にはそれほど手を加えられないので、画像のリサイズに藤 -Resizer-を使う場合と比較してみる。

<!--more-->

**以下略します。  
MeTilTran→メチル  
藤 -Resizer-→藤  
**  
まず共通の操作ですが、メチルで画像の補正をします。  
つまり、画像の傾きとノンブル削除を行います。  
そして全てPNGで吐き出しますが、そこらへんの違いで少しOCRの読み込みに差が出てくるようです。

<table border="1" cellpadding="3" cellspacing="3">
  <tr valign="top">
    <td>
      方法
    </td>
    
    <td>
      <strong>メチル補正→籐リサイズ</strong>
    </td>
    
    <td>
      メチル補正→メチルリサイズ
    </td>
    
    <td>
      メチル補正→メチルリサイズ
    </td>
  </tr>
</table>

***色深度=<span class="mw-headline">インデックスカラー</span>**  
これをe.Typistで読み込み、OCRをかける。  
以下e.Typistの設定。

・ファイル読込  
画像の微小傾き補正 → 全体の補正(T)  
(画像拡大にチェックが入ってたら外す。拡大は前で処理)  
・レイアウト → 自動レイアウト解析  
※ 読んde!!ココと違い、自動解析するほうが精度高いです。ただし、画像から  
ノンブルや柱を消して余計なものを認識しないようにする必要があります。  
・認識  
日本語認識オプション→かな  
ルビ文字挿入認識オプション  
被ルビ開始文字列 → ｜  
ルビ開始文字列 → {  
ルビ終端文字列 → }  
認識終了後の設定  
混在認識時の欧文言語 → 英語にチェック  
・ファイル保存  
保存処理 → 自動  
保存ファイル  
→ 画像名を使用してページ毎に保存  
→ ファイル形式 → テキスト

ツールメニュー → 環境設定  
・認識 → 半角文字出力 → 英、数、記号の半角出力のチェックを外す

文字認識メニュー  
領域種別指定 → 文章領域(結果は大して違いはなさそう)  
段組指定 → 縦1段  
改行コード挿入指定 → 毎行改行  
空白文字挿入指定 → 空白出力  
ルビ認識指定 → 文章中に挿入

**実行結果  
**

<table border="1" cellpadding="3" cellspacing="3">
  <tr valign="top">
    <td>
      方法
    </td>
    
    <td>
      <strong>メチル補正→籐リサイズ</strong>
    </td>
    
    <td>
      メチル補正→メチルリサイズ
    </td>
    
    <td>
      メチル補正→メチルリサイズ
    </td>
  </tr>
</table>

結果的にパターン2のメチル補正→メチルリサイズをして色深度**8bitに**するのが  
この中ではよかったが、スキャン画像により異なる反応を示すと思うので、もっと検証の必要がある。

ちなみに色深度8bitは256 色ということらしい。  
この辺が多すぎると余計なゴミも移ってしまうので、変なミスが生まれる。  
スキャンがしっかりできているほど、この影響は少なくなると思う。

他の人はどんな風にやってるのかな。(ほとんどいなそうだけど)

 [1]: http://no722.cocolog-nifty.com/blog/2007/10/index.html
 [2]: http://hp.vector.co.jp/authors/VA015850/